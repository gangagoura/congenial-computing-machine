{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <a href=\"https://cocl.us/System_ML_notebook\">\n",
    "         <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0111EN/Ad/TopAd.png\" width=\"750\" align=\"center\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai/\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0111EN/Ad/CCLog.png\" width=\"200\" align=\"center\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delay Prediction Demo Using SystemML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on datascientistworkbench.com's tutorial notebook for predicting flight delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SystemML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use one of the released version, use <code>%AddDeps org.apache.systemml systemml 1.2.0</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%AddDeps org.apache.systemml systemml 1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Spark's CSV package for loading the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%AddDeps com.databricks spark-csv_2.10 1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the airline dataset from <a href=\"stat-computing.org\">stat-computing.org<a> if not already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import java.net.URL\n",
    "import java.io.File\n",
    "val url = \"http://stat-computing.org/dataexpo/2009/2007.csv.bz2\"\n",
    "val localFilePath = \"airline2007.csv.bz2\"\n",
    "if(!new java.io.File(localFilePath).exists) {\n",
    "    new URL(url) #> new File(localFilePath) !!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into DataFrame using Spark CSV package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "val sqlContext = new SQLContext(sc)\n",
    "val fmt = sqlContext.read.format(\"com.databricks.spark.csv\")\n",
    "val opt = fmt.options(Map(\"header\"->\"true\", \"inferSchema\"->\"true\"))\n",
    "val airline = opt.load(localFilePath).na.replace( \"*\", Map(\"NA\" -> \"0.0\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airline.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Which airports have the most delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airline.registerTempTable(\"airline\")\n",
    "sqlContext.sql(\"\"\"SELECT Origin, count(*) conFlight, avg(DepDelay) delay\n",
    "                    FROM airline\n",
    "                    GROUP BY Origin\n",
    "                    ORDER BY delay DESC\"\"\").show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Logistic Regression\n",
    "\n",
    "Predict departure delays of greater than 15 of flights from JFK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.udf.register(\"checkDelay\", (depDelay:String) => try { if(depDelay.toDouble > 15) 1.0 else 2.0 } catch { case e:Exception => 1.0 })\n",
    "val tempSmallAirlineData = sqlContext.sql(\"SELECT *, checkDelay(DepDelay) label FROM airline WHERE Origin = 'JFK'\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val tempDestSet = tempSmallAirlineData.select(\"Dest\").map(y => (y.get(0).toString, 1)).groupByKey(_._1).reduceGroups((a, b) => (a._1, a._2 + b._2)).map(_._2).filter(_._2 > 1000).toDF//.collect.toList\n",
    "tempDestSet.registerTempTable(\"tempdest\")\n",
    "\n",
    "tempSmallAirlineData.registerTempTable(\"tempairline\")\n",
    "val smallAirlineData = sqlContext.sql(\"SELECT * FROM tempairline WHERE Dest in (SELECT _1 FROM tempdest)\")\n",
    "\n",
    "val datasets = smallAirlineData.randomSplit(Array(0.7, 0.3))\n",
    "val trainDataset = datasets(0).cache()\n",
    "val testDataset = datasets(1).cache()\n",
    "trainDataset.count\n",
    "testDataset.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlContext.udf.register(\"checkDelay\", (depDelay:String) => try { if(depDelay.toDouble > 15) 1.0 else 2.0 } catch { case e:Exception => 1.0 })\n",
    "val tempSmallAirlineData = sqlContext.sql(\"SELECT *, checkDelay(DepDelay) label FROM airline WHERE Origin = 'JFK'\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val popularDest = tempSmallAirlineData.select(\"Dest\").map(y => (y.get(0).toString, 1)).groupByKey(_._1).reduceGroups((a, b) => (a._1, a._2 + b._2)).map(_._2).filter(_._2 > 1000).collect.toMap\n",
    "\n",
    "sqlContext.udf.register(\"onlyUsePopularDest\", (x:String) => popularDest.contains(x))\n",
    "tempSmallAirlineData.registerTempTable(\"tempAirline\")\n",
    "println(tempSmallAirlineData)\n",
    "// val smallAirlineData = sqlContext.sql(\"SELECT * FROM tempAirline WHERE onlyUsePopularDest(Dest)\")\n",
    "\n",
    "// val datasets = smallAirlineData.randomSplit(Array(0.7, 0.3))\n",
    "// val trainDataset = datasets(0).cache()\n",
    "// val testDataset = datasets(1).cache()\n",
    "// trainDataset.count\n",
    "// testDataset.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the destination using one-hot encoding and include the columns Year, Month, DayofMonth, DayOfWeek, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\n",
    "val indexer = new StringIndexer().setInputCol(\"Dest\").setOutputCol(\"DestIndex\").setHandleInvalid(\"skip\") // Only works on Spark 1.6 or later\n",
    "val encoder = new OneHotEncoder().setInputCol(\"DestIndex\").setOutputCol(\"DestVec\")\n",
    "val assembler = new VectorAssembler().setInputCols(Array(\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"Distance\",\"DestVec\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model: Use SystemML's MLPipeline wrapper. \n",
    "\n",
    "This wrapper invokes <code>MultiLogReg.dml</code> (for training) and <code>GLM-predict.dml</code> (for prediction). These DML algorithms are available at https://github.com/apache/incubator-systemml/tree/master/scripts/algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.sysml.api.ml.LogisticRegression\n",
    "val lr = new LogisticRegression(\"log\", sc).setRegParam(1e-4).setTol(1e-2).setMaxInnerIter(0).setMaxOuterIter(100)\n",
    "val pipeline = new Pipeline().setStages(Array(indexer, encoder, assembler, lr))\n",
    "val model = pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model \n",
    "\n",
    "Output RMS error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val predictions = model.transform(testDataset.withColumnRenamed(\"label\", \"OriginalLabel\"))\n",
    "predictions.select(\"prediction\", \"OriginalLabel\").show\n",
    "sqlContext.udf.register(\"square\", (x:Double) => Math.pow(x, 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.registerTempTable(\"predictions\")\n",
    "sqlContext.sql(\"SELECT sqrt(avg(square(OriginalLabel - prediction))) FROM predictions\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<h2>Get IBM Watson Studio free of charge!</h2>\n",
    "    <p><a href=\"https://cocl.us/System_ML_notebook\"><img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0111EN/Ad/BottomAd.png\" width=\"750\" align=\"center\"></a></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
